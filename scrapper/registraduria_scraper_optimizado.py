import requests
import time
import json
import os
import sys
import re
from bs4 import BeautifulSoup
from datetime import datetime
from threading import Thread, Lock
from collections import deque

# Cargar variables de entorno desde .env
from dotenv import load_dotenv
load_dotenv()

# Importar el solver de captcha desde utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.captcha_solver import TwoCaptchaSolver

class TokenCache:
    """Sistema de cach√© de tokens reCAPTCHA compartido"""
    _instance = None
    _lock = Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        self._token_pool = deque(maxlen=10)  # Aumentado de 5 a 10 tokens
        self._pool_lock = Lock()
        self._background_thread = None
        self._keep_filling = False
        self._initialized = True
    
    def start_filler(self, api_key, sitekey, page_url):
        """Inicia el thread de background para mantener tokens disponibles"""
        if not self._keep_filling:
            self._keep_filling = True
            self._background_thread = Thread(
                target=self._fill_pool,
                args=(api_key, sitekey, page_url),
                daemon=True
            )
            self._background_thread.start()
            print("üöÄ [TokenCache] Pool de tokens iniciado en background")
    
    def warmup_pool(self, api_key, sitekey, page_url, num_tokens=2):
        """Pre-llena el pool con tokens al inicio para tener disponibles r√°pidamente"""
        def resolve_token():
            try:
                solver = TwoCaptchaSolver(api_key)
                print("üî• [Warmup] Resolviendo token inicial...")
                token = solver.solve_recaptcha_v2(site_key=sitekey, page_url=page_url, invisible=False)
                if token:
                    with self._pool_lock:
                        self._token_pool.append({
                            'token': token,
                            'timestamp': time.time()
                        })
                    print(f"‚úÖ [Warmup] Token agregado (total: {len(self._token_pool)})")
            except Exception as e:
                print(f"‚ùå [Warmup] Error: {e}")
        
        # Iniciar threads paralelos para resolver tokens
        threads = []
        for i in range(num_tokens):
            t = Thread(target=resolve_token, daemon=True)
            t.start()
            threads.append(t)
        
        print(f"üî• [Warmup] Iniciando pre-llenado de {num_tokens} tokens en paralelo...")
        return threads
    
    def _fill_pool(self, api_key, sitekey, page_url):
        """Mantiene el pool lleno de tokens v√°lidos"""
        solver = TwoCaptchaSolver(api_key)
        while self._keep_filling:
            with self._pool_lock:
                pool_size = len(self._token_pool)
            
            if pool_size < 6:  # Mantener al menos 6 tokens (aumentado de 3)
                try:
                    print("üîÑ [TokenCache] Resolviendo token...")
                    token = solver.solve_recaptcha_v2(site_key=sitekey, page_url=page_url, invisible=False)
                    if token:
                        with self._pool_lock:
                            self._token_pool.append({
                                'token': token,
                                'timestamp': time.time()
                            })
                        print(f"‚úÖ [TokenCache] Token agregado (total: {len(self._token_pool)})")
                except Exception as e:
                    print(f"‚ùå [TokenCache] Error: {e}")
            
            time.sleep(1)  # Verificar cada 1 segundo (m√°s agresivo)
    
    def get_token(self, max_age=90):
        """Obtiene un token v√°lido del pool"""
        with self._pool_lock:
            while self._token_pool:
                token_data = self._token_pool.popleft()
                age = time.time() - token_data['timestamp']
                if age < max_age:
                    print(f"‚ö° [TokenCache] Token obtenido del pool (edad: {age:.1f}s)")
                    return token_data['token']
        return None
    
    def get_pool_size(self):
        """Retorna el tama√±o actual del pool"""
        with self._pool_lock:
            return len(self._token_pool)
    
    def stop_filler(self):
        """Detiene el thread de background"""
        self._keep_filling = False

class RegistraduriaScraperAuto:
    def __init__(self, captcha_api_key, check_balance=True, token_ttl=90, enable_token_pool=True):
        self.captcha_solver = TwoCaptchaSolver(captcha_api_key)
        self.session = requests.Session()
        self.base_url = "https://eleccionescolombia.registraduria.gov.co/identificacion"
        self.api_url = "https://apiweb-eleccionescolombia.infovotantes.com/api/v1/citizen/get-information"
        self.cached_site_key = "6Lc9DmgrAAAAAJAjWVhjDy1KSgqzqJikY5z7I9SV"
        self.cached_form_data = None
        
        # Sistema de cach√© de tokens
        self.cached_token = None
        self.token_timestamp = None
        self.token_ttl = token_ttl
        self.enable_token_pool = enable_token_pool
        self.api_key = captcha_api_key
        
        # Configurar headers
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'es-ES,es;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Origin': 'https://eleccionescolombia.registraduria.gov.co',
            'Referer': 'https://eleccionescolombia.registraduria.gov.co/'
        })
        
        # Iniciar pool de tokens si est√° habilitado
        if self.enable_token_pool:
            self.token_cache = TokenCache()
            pool_size = self.token_cache.get_pool_size()
            if pool_size == 0:
                # Iniciar background filler
                self.token_cache.start_filler(self.api_key, self.cached_site_key, self.base_url)
                # Iniciar warmup en paralelo para pre-llenar el pool
                print("üî• Iniciando pre-llenado del pool...")
                self.token_cache.warmup_pool(self.api_key, self.cached_site_key, self.base_url, num_tokens=3)
            else:
                print(f"‚ôªÔ∏è  Pool de tokens ya activo ({pool_size} tokens disponibles)")
        
        # Verificar balance solo si se solicita
        if check_balance:
            balance_info = self.captcha_solver.get_balance()
            if balance_info.get('success'):
                balance = balance_info.get('balance_USD', balance_info.get('balance', 0))
                captchas = balance_info.get('estimated_captchas', 0)
                print(f"üí∞ 2captcha - ${balance:.4f} USD ({captchas} captchas disponibles)")
    
    def _is_cached_token_valid(self):
        """Verifica si el token en cach√© sigue v√°lido"""
        if not self.cached_token or not self.token_timestamp:
            return False
        
        age = time.time() - self.token_timestamp
        is_valid = age < self.token_ttl
        
        if is_valid:
            print(f"‚ö° Token en cach√© v√°lido (edad: {age:.1f}s / {self.token_ttl - age:.1f}s restantes)")
        
        return is_valid
    
    def wait_for_pool_ready(self, timeout=40):
        """Espera a que el pool tenga al menos 1 token disponible"""
        if not self.enable_token_pool:
            return True
        
        print("‚è≥ Esperando a que el pool tenga tokens disponibles...")
        start = time.time()
        
        while time.time() - start < timeout:
            pool_size = self.token_cache.get_pool_size()
            if pool_size > 0:
                elapsed = time.time() - start
                print(f"‚úÖ Pool listo con {pool_size} token(es) disponibles (esper√≥ {elapsed:.1f}s)")
                return True
            time.sleep(0.5)
        
        print(f"‚ö†Ô∏è  Timeout esperando pool, continuando de todos modos...")
        return False
    
    def solve_recaptcha(self):
        """Resuelve reCAPTCHA usando sistema de cach√© optimizado"""
        try:
            # 1. Verificar cach√© local
            if self._is_cached_token_valid():
                return self.cached_token
            
            # 2. Intentar obtener del pool
            if self.enable_token_pool:
                # Si el pool est√° vac√≠o y nunca hemos resuelto un token, esperar un poco
                if self.token_cache.get_pool_size() == 0 and not self.cached_token:
                    self.wait_for_pool_ready(timeout=40)
                
                pool_token = self.token_cache.get_token(self.token_ttl)
                if pool_token:
                    self.cached_token = pool_token
                    self.token_timestamp = time.time()
                    return pool_token
            
            # 3. Resolver nuevo token
            print(f"üîÑ Resolviendo nuevo reCAPTCHA...")
            captcha_response = self.captcha_solver.solve_recaptcha_v2(
                site_key=self.cached_site_key,
                page_url=self.base_url,
                invisible=False
            )
            
            if captcha_response:
                self.cached_token = captcha_response
                self.token_timestamp = time.time()
                print("‚úÖ reCAPTCHA resuelto")
                return captcha_response
            else:
                print("‚ùå No se pudo resolver el reCAPTCHA")
                return None
                
        except Exception as e:
            print(f"‚ùå Error al resolver reCAPTCHA: {e}")
            return None
    
    def submit_form(self, nuip, captcha_response):
        """Env√≠a el formulario a la API"""
        try:
            print("üì§ Enviando consulta a la API...")
            
            post_data = {
                "identification": str(nuip),
                "identification_type": "CC",
                "election_code": "congreso",
                "module": "polling_place",
                "platform": "web"
            }
            
            headers = self.session.headers.copy()
            headers.update({
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {captcha_response}',
                'Sec-Ch-Ua': '"Chromium";v="120", "Not_A Brand";v="99"',
                'Sec-Ch-Ua-Mobile': '?0',
                'Sec-Ch-Ua-Platform': '"Windows"',
                'Sec-Fetch-Dest': 'empty',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Site': 'cross-site',
                'Priority': 'u=1, i'
            })
            
            response = self.session.post(
                self.api_url,
                json=post_data,
                headers=headers,
                timeout=10
            )
            
            response.raise_for_status()
            
            json_response = response.json()
            print(f"‚úÖ API respondi√≥ correctamente")
            
            return json_response
        
        except requests.RequestException as e:
            print(f"‚ùå Error al enviar formulario: {e}")
            if hasattr(e, 'response') and e.response is not None:
                try:
                    error_json = e.response.json()
                    return error_json
                except:
                    pass
            return None
        except Exception as e:
            print(f"‚ùå Error general: {e}")
            return None
    
    def extract_data(self, api_response):
        """Extrae los datos de la respuesta JSON"""
        try:
            if not api_response:
                return {
                    "status": "error",
                    "message": "Respuesta vac√≠a de la API",
                    "timestamp": datetime.now().isoformat()
                }
            
            if api_response.get('status') and api_response.get('data'):
                data = api_response.get('data', {})
                polling_place = data.get('polling_place', {})
                place_address = polling_place.get('place_address', {})
                voter = data.get('voter', {})
                
                filtered_data = [{
                    'NUIP': str(voter.get('identification', '')),
                    'DEPARTAMENTO': place_address.get('state', ''),
                    'MUNICIPIO': place_address.get('town', ''),
                    'PUESTO': polling_place.get('stand', ''),
                    'DIRECCI√ìN': place_address.get('address', ''),
                    'MESA': str(polling_place.get('table', '')),
                    'ZONA': str(place_address.get('zone', ''))
                }]
                
                print(f"‚úÖ Datos extra√≠dos")
                
                result = {
                    "status": "success",
                    "timestamp": datetime.now().isoformat(),
                    "data": filtered_data,
                    "total_records": len(filtered_data),
                    "nuip": str(voter.get('identification', ''))
                }
                
                return result
            else:
                error_msg = api_response.get('message', 'Error desconocido')
                return {
                    "status": "error",
                    "message": error_msg,
                    "timestamp": datetime.now().isoformat(),
                    "api_response": api_response
                }
        
        except Exception as e:
            print(f"‚ùå Error al extraer datos: {e}")
            return {
                "status": "error",
                "message": f"Error al procesar respuesta: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }
    
    def scrape_nuip(self, nuip):
        """M√©todo principal para consultar un NUIP"""
        try:
            print(f"\n{'='*50}")
            print(f"INICIANDO CONSULTA PARA NUIP: {nuip}")
            print(f"{'='*50}")
            
            # Resolver reCAPTCHA (usar√° cach√© si est√° disponible)
            captcha_response = self.solve_recaptcha()
            if not captcha_response:
                return {
                    "status": "error",
                    "message": "No se pudo resolver el reCAPTCHA",
                    "timestamp": datetime.now().isoformat(),
                    "nuip": str(nuip)
                }
            
            # Enviar formulario
            api_response = self.submit_form(nuip, captcha_response)
            
            # Si falla con el token actual (403), intentar con nuevo token del pool
            if api_response and not api_response.get('status'):
                print("‚ö†Ô∏è Token usado, obteniendo nuevo token del pool...")
                # Invalidar cach√©
                self.cached_token = None
                self.token_timestamp = None
                # Obtener nuevo token
                captcha_response = self.solve_recaptcha()
                if captcha_response:
                    api_response = self.submit_form(nuip, captcha_response)
            
            # Extraer datos
            result = self.extract_data(api_response)
            
            print(f"‚úÖ CONSULTA COMPLETADA PARA NUIP: {nuip}\n")
            
            return result
            
        except Exception as e:
            print(f"‚ùå Error al consultar NUIP {nuip}: {e}")
            return {
                "status": "error",
                "message": f"Error en la consulta: {str(e)}",
                "timestamp": datetime.now().isoformat(),
                "nuip": str(nuip)
            }
    
    def scrape_multiple_nuips(self, nuips, delay=2):
        """Consulta m√∫ltiples NUIPs con delay entre cada una"""
        results = {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "total_nuips": len(nuips),
            "results": []
        }
        
        for i, nuip in enumerate(nuips, 1):
            print(f"\nüìã Consultando NUIP {i}/{len(nuips)}: {nuip}")
            
            result = self.scrape_nuip(nuip)
            results["results"].append(result)
            
            if i < len(nuips):
                print(f"‚è≥ Esperando {delay} segundos...")
                time.sleep(delay)
        
        return results
    
    def close(self):
        """Cierra la sesi√≥n"""
        if self.session:
            self.session.close()
            print("üîí Sesi√≥n cerrada")

# Funci√≥n para guardar resultados
def save_registraduria_results(data, filename=None):
    """Guarda los resultados en un archivo JSON"""
    if filename is None:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        results_dir = "resultados"
        os.makedirs(results_dir, exist_ok=True)
        filename = os.path.join(results_dir, f"consulta_registraduria_{timestamp}.json")
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"üíæ Resultados guardados en: {filename}")
    return filename

# Ejemplo de uso
if __name__ == "__main__":
    API_KEY = os.getenv('APIKEY_2CAPTCHA')
    
    if not API_KEY:
        print("‚ùå Error: No se encontr√≥ la API key de 2captcha")
        sys.exit(1)
    
    print(f"üîë API Key cargada: {API_KEY[:10]}...")
    
    # Crear scraper con pool de tokens habilitado (sin verificar balance para ser m√°s r√°pido)
    scraper = RegistraduriaScraperAuto(API_KEY, check_balance=False, enable_token_pool=True)
    
    try:
        # Ejemplo: Consultar un NUIP
        nuip_ejemplo = "1102877148"
        resultado = scraper.scrape_nuip(nuip_ejemplo)
        
        print(f"\nüìä RESULTADO FINAL:")
        print(json.dumps(resultado, indent=2, ensure_ascii=False))
        
        save_registraduria_results(resultado)
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Proceso interrumpido por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error cr√≠tico: {e}")
    finally:
        scraper.close()
